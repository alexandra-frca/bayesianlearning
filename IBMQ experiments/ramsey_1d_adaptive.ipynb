{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ramsey_1d_adaptive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfp627fjnwTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9cd808-5e41-4c40-dcdf-82fee2e83c30"
      },
      "source": [
        "!pip install 'qiskit[visualization]' --quiet\n",
        "save_and_load = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 6.0MB 13.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 18.0MB 126kB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 42.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 55.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 34.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 26.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 44.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 614kB 45.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 32.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.3MB 29.5MB/s \n",
            "\u001b[?25h  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docplex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dlx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEEbwskenyR5",
        "outputId": "387b1ba9-ac58-4936-aea1-45d6bf3c7c7f"
      },
      "source": [
        "import random, numpy as np, matplotlib.pyplot as plt, pickle\n",
        "from scipy.optimize import curve_fit\n",
        "from google.colab import files\n",
        "from qiskit import execute\n",
        "from qiskit import pulse            \n",
        "from qiskit.pulse import Play\n",
        "from qiskit.pulse import library as pulse_lib\n",
        "from qiskit.ignis.characterization.calibrations import rabi_schedules,RabiFitter\n",
        "from qiskit.tools.monitor import job_monitor\n",
        "from qiskit.providers.ibmq import least_busy\n",
        "\n",
        "from qiskit import IBMQ\n",
        "API_KEY = 'd1e0708e9ea899bf5a17e43c1b948223b9c9b66e19dfb58a40fc20b0ee383b8595ef447b340a57fa6e3b9da49c9711efbec30a8a68c77ab235e42662cbba1a62'\n",
        "\n",
        "if save_and_load: # First time run.\n",
        "  IBMQ.save_account(API_KEY, overwrite=True)\n",
        "  IBMQ.load_account()\n",
        "  save_and_load = False\n",
        "\n",
        "# Channel delays seem to have to be multiples of 16 for >1 qubit backends?\n",
        "def get_closest_multiple_of_16(num):\n",
        "    return int(num + 8 ) - (int(num + 8 ) % 16)\n",
        "\n",
        "specific_choice = False\n",
        "nqubits = 1\n",
        "exclude = None\n",
        "\n",
        "mock_backend = False\n",
        "if mock_backend:\n",
        "  from qiskit.providers.aer import PulseSimulator\n",
        "  from qiskit.test.mock.backends.armonk.fake_armonk import FakeArmonk\n",
        "  from qiskit.providers.aer.pulse import PulseSystemModel\n",
        "  armonk_backend = FakeArmonk()\n",
        "  armonk_model = PulseSystemModel.from_backend(armonk_backend)\n",
        "  backend = PulseSimulator()\n",
        "  # Must change functions too. See https://qiskit.org/documentation/tutorials/circuits_advanced/10_pulse_simulator_backend_model.html\n",
        "elif nqubits is not None and nqubits==1:\n",
        "  provider = IBMQ.get_provider(hub='ibm-q', group='open', project='main')\n",
        "  backend = provider.get_backend('ibmq_armonk')\n",
        "  print(\"Selected single qubit backend: \", backend, end=\"\")\n",
        "elif specific_choice:\n",
        "  provider=IBMQ.get_provider(hub='ibm-q-minho', group='academicprojects', project='quantalab')\n",
        "  backend = provider.get_backend('ibmq_guadalupe')\n",
        "  print(\"Selected backend: \", backend, end=\"\")\n",
        "else:\n",
        "  provider=IBMQ.get_provider(hub='ibm-q-minho', group='academicprojects', project='quantalab')\n",
        "  conditional_backends = provider.backends(filters=lambda x: \n",
        "                            (nqubits is None or x.configuration().n_qubits==nqubits)\n",
        "                            and not x.configuration().simulator \n",
        "                            and x.configuration().backend_name != exclude\n",
        "                            and x.configuration().open_pulse is True)\n",
        "  backend = least_busy(conditional_backends,reservation_lookahead=2*60)\n",
        "  print(\"Selected least busy backend: \", backend,end=\"\")\n",
        "\n",
        "\n",
        "q = 0 # The index of the qubit to be considered.\n",
        "\n",
        "defaults = backend.defaults()\n",
        "properties = backend.properties()\n",
        "time_unit = properties.gate_length(\"id\", [q])\n",
        "print(\" (time resolution: %.2f ns)\" % (time_unit*1e9))\n",
        "configuration = backend.configuration()\n",
        "job_limit = backend.job_limit()\n",
        "maxjobs = job_limit.maximum_jobs\n",
        "print(\"Maximum pending jobs allowed per user: \", \n",
        "      \"no limit\" if maxjobs is None else maxjobs)\n",
        "print(configuration.to_dict())\n",
        "\n",
        "t1_est = properties.t1(q)\n",
        "t2_est = properties.t2(q)\n",
        "freq_est = properties.frequency(q) \n",
        "# ^Same as backend.defaults().qubit_freq_est[0] which is the default for driving\n",
        "#channel.\n",
        "\n",
        "print(\"The estimated backend properties for qubit %d are:\" % q)\n",
        "print(\"* Resonance frequency: %.2f gigahertz\" % (freq_est*1e-9))\n",
        "print(\"* T1 time: %.1f microseconds\" % (t1_est*1e6))\n",
        "print(\"* T2 time: %.1f microseconds\" % (t2_est*1e6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected single qubit backend:  ibmq_armonk (time resolution: 71.11 ns)\n",
            "Maximum pending jobs allowed per user:  5\n",
            "{'backend_name': 'ibmq_armonk', 'backend_version': '2.4.10', 'n_qubits': 1, 'basis_gates': ['id', 'rz', 'sx', 'x'], 'gates': [{'name': 'id', 'parameters': [], 'qasm_def': 'gate id q { U(0, 0, 0) q; }', 'coupling_map': [[0]]}, {'name': 'rz', 'parameters': ['theta'], 'qasm_def': 'gate rz(theta) q { U(0, 0, theta) q; }', 'coupling_map': [[0]]}, {'name': 'sx', 'parameters': [], 'qasm_def': 'gate sx q { U(pi/2, 3*pi/2, pi/2) q; }', 'coupling_map': [[0]]}, {'name': 'x', 'parameters': [], 'qasm_def': 'gate x q { U(pi, 0, pi) q; }', 'coupling_map': [[0]]}], 'local': False, 'simulator': False, 'conditional': False, 'open_pulse': True, 'memory': True, 'max_shots': 8192, 'coupling_map': None, 'dynamic_reprate_enabled': False, 'supported_instructions': ['x', 'setf', 'u3', 'u2', 'acquire', 'shiftf', 'u1', 'sx', 'measure', 'id', 'delay', 'play', 'rz'], 'max_experiments': 75, 'sample_name': 'family: Canary, revision: 1.2', 'n_registers': 1, 'credits_required': True, 'online_date': datetime.datetime(2019, 10, 16, 4, 0, tzinfo=tzutc()), 'description': '1 qubit device', 'dt': 0.2222222222222222, 'dtm': 0.2222222222222222, 'processor_type': {'family': 'Canary', 'revision': 1.2}, 'allow_q_object': True, 'multi_meas_enabled': True, 'parametric_pulses': ['gaussian', 'gaussian_square', 'drag', 'constant'], 'quantum_volume': 1, 'qubit_channel_mapping': [['d0', 'm0']], 'uchannels_enabled': True, 'url': 'None', 'input_allowed': ['job'], 'allow_object_storage': True, 'pulse_num_channels': 9, 'pulse_num_qubits': 3, 'n_uchannels': 0, 'u_channel_lo': [], 'meas_levels': [1, 2], 'qubit_lo_range': [[4.471663385532677, 5.471663385532677]], 'meas_lo_range': [[6.493370669000001, 7.493370669000001]], 'meas_kernels': ['hw_boxcar'], 'discriminators': ['quadratic_discriminator', 'linear_discriminator'], 'rep_times': [1000.0], 'meas_map': [[0]], 'acquisition_latency': [], 'conditional_latency': [], 'hamiltonian': {'description': 'Qubits are modeled as Duffing oscillators. In this case, the system includes higher energy states, i.e. not just |0> and |1>. The Pauli operators are generalized via the following set of transformations:\\n\\n$(\\\\mathbb{I}-\\\\sigma_{i}^z)/2 \\\\rightarrow O_i \\\\equiv b^\\\\dagger_{i} b_{i}$,\\n\\n$\\\\sigma_{+} \\\\rightarrow b^\\\\dagger$,\\n\\n$\\\\sigma_{-} \\\\rightarrow b$,\\n\\n$\\\\sigma_{i}^X \\\\rightarrow b^\\\\dagger_{i} + b_{i}$.\\n\\nQubits are coupled through resonator buses. The provided Hamiltonian has been projected into the zero excitation subspace of the resonator buses leading to an effective qubit-qubit flip-flop interaction. The qubit resonance frequencies in the Hamiltonian are the cavity dressed frequencies and not exactly what is returned by the backend defaults, which also includes the dressing due to the qubit-qubit interactions.\\n\\nQuantities are returned in angular frequencies, with units 2*pi*GHz.\\n\\nWARNING: Currently not all system Hamiltonian information is available to the public, missing values have been replaced with 0.\\n', 'h_latex': '\\\\begin{align} \\\\mathcal{H}/\\\\hbar = & \\\\sum_{i=0}^{0}\\\\left(\\\\frac{\\\\omega_{q,i}}{2}(\\\\mathbb{I}-\\\\sigma_i^{z})+\\\\frac{\\\\Delta_{i}}{2}(O_i^2-O_i)+\\\\Omega_{d,i}D_i(t)\\\\sigma_i^{X}\\\\right) \\\\\\\\ \\\\end{align}', 'h_str': ['_SUM[i,0,0,wq{i}/2*(I{i}-Z{i})]', '_SUM[i,0,0,delta{i}/2*O{i}*O{i}]', '_SUM[i,0,0,-delta{i}/2*O{i}]', '_SUM[i,0,0,omegad{i}*X{i}||D{i}]'], 'osc': {}, 'qub': {'0': 3}, 'vars': {'delta0': -2.1814775258495027, 'omegad0': 0.11857321204721068, 'wq0': 31.237882336221634}}, 'channels': {'acquire0': {'operates': {'qubits': [0]}, 'purpose': 'acquire', 'type': 'acquire'}, 'd0': {'operates': {'qubits': [0]}, 'purpose': 'drive', 'type': 'drive'}, 'm0': {'operates': {'qubits': [0]}, 'purpose': 'measure', 'type': 'measure'}}}\n",
            "The estimated backend properties for qubit 0 are:\n",
            "* Resonance frequency: 4.97 gigahertz\n",
            "* T1 time: 109.3 microseconds\n",
            "* T2 time: 231.3 microseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jrHpGk8nlnZ"
      },
      "source": [
        "f_real = 1.83\n",
        "\n",
        "def get_echoed_ramsey_schedule(t, delta_f):\n",
        "    # Need to convert evolution times to backend time units/samples.\n",
        "    with pulse.build(backend):\n",
        "      samples = pulse.builder.seconds_to_samples(t/2)\n",
        "    delay = get_closest_multiple_of_16(samples)\n",
        "    \n",
        "    dq = pulse.DriveChannel(q)\n",
        "    mq = pulse.MeasureChannel(q)\n",
        "    with pulse.build(backend,name=f\"Ramsey delay\") as schedule:\n",
        "      with pulse.align_sequential():\n",
        "        pulse.set_frequency(freq_est + delta_f, dq)\n",
        "        pulse.u2(0,np.pi,q) # Half pi rotation.\n",
        "        pulse.delay(delay,mq)\n",
        "        pulse.set_frequency(freq_est - delta_f, dq)\n",
        "        pulse.x(q) # Pi rotation.\n",
        "        pulse.delay(delay,mq)\n",
        "        pulse.set_frequency(freq_est + delta_f, dq)\n",
        "        pulse.u2(0,np.pi,q) \n",
        "        pulse.measure(q)  \n",
        "\n",
        "    return schedule\n",
        "\n",
        "def run_echoed_ramsey_job_single(t, delta_f):\n",
        "    ramsey_schedule = get_echoed_ramsey_schedule(t, delta_f)\n",
        "    echoed_ramsey_job = backend.run(ramsey_schedule,meas_level=2,shots=1)\n",
        "    ID = echoed_ramsey_job.job_id()\n",
        "    #print(f\"Echoed ramsey job ID: '{ID}' [run_echoed_ramsey_job]\")\n",
        "    job_monitor(echoed_ramsey_job)\n",
        "    return echoed_ramsey_job\n",
        "\n",
        "def measure_IBMQ(t):\n",
        "    delta_f = f_real*1e6\n",
        "    ramsey_job_single = run_echoed_ramsey_job_single(t*1e-6, delta_f)\n",
        "    result = ramsey_job_single.result()\n",
        "    dict = result.get_counts()\n",
        "    outcome = int(list(dict.keys())[0])\n",
        "    # Flip the outcomes because the code is structured oppositely to\n",
        "    #the IBM experiments.\n",
        "    outcome = outcome^1\n",
        "    return outcome"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIIkRMj52GNn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b540838f-dbc7-4952-8b9b-c9e7e7862500"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Hamiltonian learning implementation for a simple precession example, using both\n",
        "offline and adaptive Bayesian inference.\n",
        "The qubit is assumed to be initialized at state |+> for each iteration, and to\n",
        "evolve under H = f*sigma_z/2, where f is the parameter to be estimated.\n",
        "A sequential Monte Carlo approximation is used to represent the probability \n",
        "distributions, using Hamiltonian Monte Carlo and Metropolis-Hastings mutation \n",
        "steps when some threshold effective sample size is crossed.\n",
        "The evolution of the standard deviations the \"precisions\" (the variance times \n",
        "the cumulative evolution time) with the steps are plotted, and the final values \n",
        "of these quantities (in addition to the actual error) are printed.\n",
        "The algorithm is repeated for a number of runs with randomly picked real\n",
        "values, and medians are taken over all of them to get the results and graphs.\n",
        "\"\"\"\n",
        "\n",
        "import sys, random, copy, pickle, matplotlib.pyplot as plt\n",
        "from autograd import grad, numpy as np\n",
        "np.seterr(all='warn')\n",
        "\n",
        "dim=1\n",
        "total_HMC, accepted_HMC = 0, 0\n",
        "total_MH, accepted_MH = 0, 0\n",
        "\n",
        "N_particles = 100 # Number of samples used to represent the probability\n",
        "#distribution, using a sequential Monte Carlo approximation.\n",
        "\n",
        "f_real = 0 # The actual precession frequency we mean to estimate \n",
        "#(will be picked at random for each run).\n",
        "\n",
        "fmin, fmax = 0, 10 \n",
        "\n",
        "def measure(t, real_data = False):\n",
        "    '''\n",
        "    Simulates the measurement of the quantum system of the x component of spin \n",
        "    at a given time t after initialization at state |+>.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    t: float\n",
        "        The evolution time between the initialization and the projection.\n",
        "    alpha: int, optional\n",
        "        The exponential decay parameter (Default is 0).\n",
        "    tries: int, optional\n",
        "        The amount of times the measurement is repeated (Default is 1).\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    1 if the result is |+>, 0 if it is |->.\n",
        "    '''\n",
        "    if real_data:\n",
        "      return measure_IBMQ(t)\n",
        "    else:\n",
        "      r = random.random()\n",
        "      p = np.cos(2*np.pi*f_real*t/2)**2\n",
        "      if (r<p):\n",
        "          return 1\n",
        "      return 0\n",
        "\n",
        "def simulate_1(test_f, t):\n",
        "    '''\n",
        "    Provides an estimate for the likelihood  P(D=1|test_f,t) of an x-spin \n",
        "    measurement at time t yielding result |+>, given a test parameter for the \n",
        "    fixed form Hamiltonian. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    test_f: float\n",
        "        The test precession frequency.\n",
        "    t: float\n",
        "        The evolution time between the initialization and the projection.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    p1: float\n",
        "        The estimated probability of finding the particle at state |+>.\n",
        "    '''\n",
        "    p1 = np.cos(2*np.pi*test_f*t/2)**2\n",
        "    return p1\n",
        "\n",
        "def likelihood(data, test_f):\n",
        "    '''\n",
        "    Provides an estimate for the likelihood  P(D|test_f,t) of an x-spin \n",
        "    measurement at time t yielding a given result, given a test parameter for  \n",
        "    the fixed form Hamiltonian. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: [(float,int)]\n",
        "        A vector of experimental results and controls, each datum being of the \n",
        "        form (time,outcome), where 'time' is the control used for each \n",
        "        experiment and 'outcome' is its result.\n",
        "    test_f: float\n",
        "        The test precession frequency.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    p: float\n",
        "        The estimated probability of obtaining the input outcome. \n",
        "    '''\n",
        "    if np.size(data)==2:\n",
        "        t,outcome = data if len(data)==2 else data[0] # May be wrapped in array.\n",
        "        p = simulate_1(test_f,t)*(outcome==1)+\\\n",
        "            (1-simulate_1(test_f,t))*(outcome==0) \n",
        "    else:\n",
        "        p = np.product([likelihood(datum, test_f) for datum in data])\n",
        "    return p \n",
        "\n",
        "def loglikelihood(data, test_f):\n",
        "    '''\n",
        "    Provides an estimate for the likelihood  P(D|test_f,t) of an x-spin \n",
        "    measurement at time t yielding a given result, given a test parameter for  \n",
        "    the fixed form Hamiltonian. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: [(float,int)]\n",
        "        A vector of experimental results and controls, each datum being of the \n",
        "        form (time,outcome), where 'time' is the control used for each \n",
        "        experiment and 'outcome' is its result.\n",
        "    test_f: float\n",
        "        The test precession frequency.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    p: float\n",
        "        The estimated probability of obtaining the input outcome. \n",
        "    '''\n",
        "    p = np.sum([np.log(likelihood(datum, test_f)) for datum in data])\n",
        "    return p \n",
        "\n",
        "def U_gradient(data,test_f,autograd=False):\n",
        "    '''\n",
        "    Evaluates the derivative of the target \"energy\" associated to the likelihood \n",
        "    at a time t seen as a probability density, given a frequency for the fixed \n",
        "    form Hamiltonian. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: [(float,int)]\n",
        "        A vector of experimental results and controls, each datum being of the \n",
        "        form (time,outcome), where 'time' is the control used for each \n",
        "        experiment and 'outcome' is its result.\n",
        "    test_f: float\n",
        "        The frequency to be used for the likelihood.\n",
        "    autograd: bool, optional\n",
        "        Whether to use automatic differenciation (Default is False).\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    DU: float\n",
        "        The derivative of the \"energy\".\n",
        "    '''\n",
        "    \n",
        "    '''\n",
        "    The cosine must be different from 0 if the outcome is 1, and from -1/1 if \n",
        "    the outcome is 0 (so that the divisor is non-zero when evaluating the            \n",
        "    derivative).\n",
        "    '''\n",
        "    usable_data = [(t,outcome) for (t,outcome) in data \n",
        "            if (np.cos(test_f*t/2)!=1 or outcome!=1)\n",
        "            and (abs(np.cos(test_f*t/2))!=1 or outcome!=0)]\n",
        "    \n",
        "    if autograd: \n",
        "        minus_DU_f = grad(loglikelihood,1)\n",
        "        DU = -minus_DU_f(usable_data,float(test_f))\n",
        "    else:\n",
        "        DU = 0\n",
        "        for (t,outcome) in usable_data:\n",
        "            if outcome==1:\n",
        "                DU+=t*np.sin(test_f*t/2)/np.cos(test_f*t/2)\n",
        "            if outcome==0:\n",
        "                DU-=t*np.sin(test_f*t/2)*np.cos(test_f*t/2)/\\\n",
        "                np.sin(test_f*t/2)**2\n",
        "    return(DU)\n",
        "\n",
        "def gaussian(x, mu, sigma, normalize=False):\n",
        "    '''\n",
        "    Evaluates a gaussian function at a given point for some specified set of\n",
        "    parameters.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    x: float\n",
        "        The point at which the function is to be evaluated.\n",
        "    mu: float\n",
        "        The mean to be used for the gaussian function.\n",
        "    sigma: float\n",
        "        The standard deviation to be used for the gaussian function.\n",
        "    normalize: bool, optional\n",
        "        Whether to normalize the result (Default is False).\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    e: float\n",
        "        The value of the gaussian function at the provided point.\n",
        "    '''\n",
        "    power = -(x-mu)**2/(2*sigma**2)\n",
        "    if not normalize:\n",
        "        e = np.exp(power)\n",
        "        return e\n",
        "    else:\n",
        "        norm = (2*np.pi*sigma**2)**0.5  \n",
        "        e = e/norm\n",
        "        return e\n",
        "\n",
        "first_metropolis_hastings_step = True\n",
        "def metropolis_hastings_step(data, particle, s=1, factor=0.1,\n",
        "                             left_constraint = fmin,right_constraint=fmax): \n",
        "    '''\n",
        "    Performs a Metropolis-Hastings mutation on a given particle, using a \n",
        "    gaussian function for the proposals.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: [(float,int)]\n",
        "        A vector of experimental results obtained so far and their respective \n",
        "        controls, each datum being of the form (time,outcome), where 'time' is          \n",
        "        the control used for each experiment and 'outcome' is its result.\n",
        "    particle: float\n",
        "        The particle to undergo a mutation step.\n",
        "    s: float, optional\n",
        "        The standard deviation to be multiplied by a factor and then used as \n",
        "        standard deviation for the normal distribution used for the proposal \n",
        "        (Default is 1).\n",
        "    factor: float, optional\n",
        "        The factor 's' should be be multiplied by to get the standard deviation\n",
        "        of the the normal distribution used for the proposal (Default is 0.05).\n",
        "    left_constraint: float\n",
        "        The leftmost bounds to be enforced for the particle's motion.\n",
        "    right_constraint: float\n",
        "        The rightmost bounds to be enforced for the particle's motion.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    particle: float\n",
        "        The mutated particle.\n",
        "    p: float\n",
        "        The acceptance probability to be used for the evolved particle as a \n",
        "        Monte Carlo proposal.\n",
        "    '''\n",
        "    global first_metropolis_hastings_step\n",
        "    if first_metropolis_hastings_step:\n",
        "      if (s!=1):\n",
        "          sigma = \"sigma\"\n",
        "      else:\n",
        "          cov = \"1\"\n",
        "      print(\"MH:  s=%s, factor=%.4f\" % (sigma,factor))\n",
        "      first_metropolis_hastings_step = False\n",
        "\n",
        "    sigma = s**0.5*factor # Numpy normal uses stdev, not variance.\n",
        "\n",
        "    # Start with any invalid value.\n",
        "    new_particle = left_constraint-1\n",
        "    \n",
        "    # Get a proposal that satisfies the constraints.\n",
        "    while (new_particle < left_constraint or new_particle > right_constraint):\n",
        "        new_particle = np.random.normal(particle, sigma)\n",
        "        \n",
        "    # Compute the probabilities of transition for the acceptance probability.\n",
        "    p = likelihood(data,new_particle)*gaussian(particle,new_particle,\n",
        "                                                    sigma)/ \\\n",
        "        (likelihood(data,particle)*gaussian(new_particle,particle,sigma))\n",
        "    return new_particle,p\n",
        "\n",
        "def simulate_dynamics(data, initial_momentum, initial_particle, m, L, eta,\n",
        "                      left_constraint = 0, right_constraint=10):    \n",
        "    '''\n",
        "    Simulates Hamiltonian dynamics for a given particle, using leapfrog \n",
        "    integration.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: [(float,int)]\n",
        "        A vector of experimental results obtained so far and their respective \n",
        "        controls, each datum being of the form (time,outcome), where 'time' is          \n",
        "        the control used for each experiment and 'outcome' is its result.\n",
        "    initial_momentum: float\n",
        "        The starting momentum vector. \n",
        "    initial_particle: float\n",
        "        The particle for which the Hamiltonian dynamics is to be simulated.\n",
        "    m: float\n",
        "        The mass to be used when simulating the Hamiltonian dynamics (a HMC \n",
        "        tuning parameter).\n",
        "    L: int\n",
        "        The amount of integration steps to be used when simulating the \n",
        "        Hamiltonian dynamics (a HMC tuning parameter).\n",
        "    eta: float\n",
        "        The integration stepsize to be used when simulating the Hamiltonian \n",
        "        dynamics (a HMC tuning parameter).\n",
        "    left_constraints: float\n",
        "        The leftmost bound to be enforced for the particle's motion.\n",
        "    right_constraints: float\n",
        "        The rightmost bound to be enforced for the particle's motion.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    particle: float\n",
        "        The particle having undergone motion.\n",
        "    p: float\n",
        "        The acceptance probability to be used for the evolved particle as a \n",
        "        Monte Carlo proposal.\n",
        "    '''    \n",
        "    new_particle = initial_particle\n",
        "    DU = U_gradient(data,new_particle)\n",
        "    global f_real\n",
        "    \n",
        "    # Perform leapfrog integration according to Hamilton's equations.\n",
        "    new_momentum = initial_momentum - 0.5*eta*DU\n",
        "    for l in range(L):\n",
        "        new_particle = new_particle + eta*new_momentum/m\n",
        "        \n",
        "        # Enforce the constraint that both the frequency lie within the prior \n",
        "        #distribution. \n",
        "        # Should a limit be crossed, the position and momentum are chosen such \n",
        "        #that the particle \"rebounds\".\n",
        "        if (new_particle < left_constraint):\n",
        "            new_particle = left_constraint+(left_constraint-new_particle)\n",
        "            new_momentum = -new_momentum\n",
        "        if (new_particle > right_constraint): # Use the upper limit from the \n",
        "        #prior.\n",
        "            new_particle = right_constraint-(new_particle-right_constraint)\n",
        "            new_momentum = -new_momentum\n",
        "        DU = U_gradient(data,new_particle)\n",
        "        if (l != L-1):\n",
        "            new_particle = new_particle - eta*DU\n",
        "    new_momentum = new_momentum - 0.5*eta*DU\n",
        "\n",
        "\n",
        "    p = np.exp(-loglikelihood(data,initial_particle)-\\\n",
        "               (-loglikelihood(data,new_particle))+\\\n",
        "                   initial_momentum**2/(2*m)-new_momentum**2/(2*m))\n",
        "    \n",
        "    '''\n",
        "    if (p<0.1):\n",
        "        sys.exit('p too small')\n",
        "    '''\n",
        "    \n",
        "    return new_particle, p\n",
        "        \n",
        "first = True\n",
        "def hamiltonian_MC_step(data, point, m=1, L=20, eta=10**-4, \n",
        "                        threshold=1):\n",
        "    '''\n",
        "    Performs a Hamiltonian Monte Carlo mutation on a given particle.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: [(float,int)]\n",
        "        A vector of experimental results obtained so far and their respective \n",
        "        controls, each datum being of the form (time,outcome), where 'time' is          \n",
        "        the control used for each experiment and 'outcome' is its result.\n",
        "    t: float\n",
        "        The time at which the current iteration's measurement was performed.\n",
        "        This is relevant because the target function and its derivative are \n",
        "        time-dependent.\n",
        "    particle: float\n",
        "        The frequency particle to undergo a mutation step.\n",
        "    m: float, optional\n",
        "        The mass to be used when simulating the Hamiltonian dynamics (a HMC \n",
        "        tuning parameter) (Default is 1).\n",
        "    L: int, optional\n",
        "        The amount of integration steps to be used when simulating the \n",
        "        Hamiltonian dynamics (a HMC tuning parameter) (Default is 20).\n",
        "    eta: float, optional\n",
        "        The integration stepsize to be used when simulating the Hamiltonian \n",
        "        dynamics (a HMC tuning parameter) (Default is exp(-4)).\n",
        "    threshold: float, optional\n",
        "        The highest HMC acceptance rate that should trigger a Metropolis-\n",
        "        -Hastings mutation step (as an alternative to a  HMC mutation step) \n",
        "        (Default is 0.1). \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    particle: float\n",
        "        The mutated frequency particle.\n",
        "    '''\n",
        "    if (threshold<1):\n",
        "        print(\"The HMC implementation is outdated and there's a factor of\"\n",
        "        \" 2*np.pi missing in the gradients (so f would be angular freq), fix it\")\n",
        "        # Perform a Hamiltonian Monte Carlo mutation.\n",
        "        global first\n",
        "        if first:\n",
        "            if (m!=1):\n",
        "                mass = \"cov\"\n",
        "            else:\n",
        "                mass = \"1\"\n",
        "            print(\"HMC: m=%s, L=%d, eta=%f\" % (mass,L,eta))\n",
        "            first = False\n",
        "            \n",
        "        global total_HMC, accepted_HMC, total_MH, accepted_MH\n",
        "        initial_momentum = np.random.normal(0, scale=m)\n",
        "        new_point, p = simulate_dynamics(data,initial_momentum,point,\n",
        "                                         m,L,eta)\n",
        "    else:\n",
        "        p = 0\n",
        "        \n",
        "    # If the Hamiltonian Monte Carlo acceptance probability is too low,\n",
        "    #a Metropolis-Hastings mutation will be performed instead.\n",
        "    # This is meant to saufegard the termination of the program if the leapfrog\n",
        "    #integration is too inaccurate for a given set of parameters and experiment\n",
        "    #controls (which tends to happen close to or at the assymptotes of the log-\n",
        "    #-likelihood).\n",
        "    \n",
        "    if (p < threshold):\n",
        "        MH = True\n",
        "        new_point, p = metropolis_hastings_step(data,point,s=1/m)\n",
        "        total_MH += 1\n",
        "    else:\n",
        "        MH = False\n",
        "        total_HMC += 1\n",
        "        \n",
        "    a = min(1,p)\n",
        "    if (np.random.rand() < a):\n",
        "        if MH:\n",
        "            accepted_MH += 1\n",
        "        else:\n",
        "            accepted_HMC += 1\n",
        "        return(new_point)\n",
        "    else:\n",
        "        return(point)\n",
        "\n",
        "def bayes_update(data, distribution, threshold=N_particles/2):\n",
        "    '''\n",
        "    Updates a prior distribution according to the outcome of a measurement, \n",
        "    using Bayes' rule. \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: [(float,int)]\n",
        "        A vector of experimental results obtained so far and their respective \n",
        "        controls, each datum being of the form (time,outcome), where 'time' is          \n",
        "        the control used for each experiment and 'outcome' is its result.\n",
        "    distribution: dict\n",
        "        , with (key,value):=(frequency particle,importance weight)\n",
        "        The prior distribution (SMC approximation). When returning, it will \n",
        "        have been updated according to the provided experimental datum.\n",
        "    threshold: float, optional\n",
        "        The threshold effective sample size that should trigger a resampling \n",
        "        step (Default is N_particles/2). \n",
        "        \n",
        "    t: float\n",
        "        The time at which the measurement was performed, which characterizes \n",
        "        it. The reference (t=0) is taken as the time of initialization.\n",
        "    '''\n",
        "    global N_particles\n",
        "    acc_weight = 0\n",
        "    acc_squared_weight = 0\n",
        "    \n",
        "    # Update weights based on last likelihood obtained (as in SMC). \n",
        "    for particle in distribution:\n",
        "        new_weight = likelihood(data[-1],particle)*distribution[particle]\n",
        "        distribution[particle] = new_weight\n",
        "        acc_weight += new_weight\n",
        "    \n",
        "    # Normalize the weights.\n",
        "    for particle in distribution:\n",
        "        w = distribution[particle]/acc_weight\n",
        "        distribution[particle] = w\n",
        "        acc_squared_weight += w**2 # The inverse participation ratio will be\n",
        "        #used to decide whether to resample.\n",
        "\n",
        "    if (1/acc_squared_weight <= threshold):\n",
        "        selected_particles = random.choices(list(distribution.keys()), \n",
        "                                              weights=distribution.values(),\n",
        "                                              k=N_particles)\n",
        "        distribution.clear()\n",
        "      \n",
        "        cov = SMCparameters(selected_particles,list=True)[1]**2\n",
        "        # The covariance will be used as a mass, so it must be positive.\n",
        "        if (cov==0):\n",
        "            return\n",
        "        \n",
        "        for particle in selected_particles:\n",
        "            new_particle = hamiltonian_MC_step(data, particle, m=1/cov)\n",
        "            if new_particle not in distribution:\n",
        "                distribution[new_particle] = 1/N_particles\n",
        "            else:\n",
        "                distribution[new_particle] += 1/N_particles\n",
        "    return(distribution)\n",
        "\n",
        "def SMCparameters(distribution, stdev=True, list=False):\n",
        "    '''\n",
        "    Calculates the mean and (optionally) standard deviation of a given \n",
        "    distribution.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    distribution: dict\n",
        "        , with (key,value):=(frequency particle,importance weight)\n",
        "        The distribution (SMC approximation) whose parameters are to be \n",
        "        calculated.\n",
        "    stdev: bool\n",
        "        To be set to False if the standard deviation is not to be returned \n",
        "        (Default is True).\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    mean: float\n",
        "        The mean of the distribution.\n",
        "    stdev: float\n",
        "        The standard deviation of the distribution.\n",
        "    '''\n",
        "    mean = 0\n",
        "    meansquare = 0\n",
        "    for particle in distribution:\n",
        "        f = particle\n",
        "        if list: # Distribution is given as a dictionary with implicitly \n",
        "        #uniform weights.\n",
        "            w = 1/len(distribution)\n",
        "        else: # Distribution is given by a dictionary with values as weights.\n",
        "            w = distribution[particle]\n",
        "        mean += f*w\n",
        "        meansquare += f**2*w\n",
        "    if not stdev:\n",
        "        return mean\n",
        "    stdev = abs(mean**2-meansquare)**0.5\n",
        "    return mean,stdev\n",
        "\n",
        "def offline_estimation(distribution, data):\n",
        "    '''\n",
        "    Estimates the precession frequency by defining a set of experiments, \n",
        "    performing them, and updating a given prior distribution according to their \n",
        "    outcomes (using Bayesian inference).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    distribution: dict\n",
        "        , with (key,value):=(frequency particle,importance weight)\n",
        "        The prior distribution (SMC approximation).\n",
        "    steps: int\n",
        "        The total number of experiments to be performed.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    mean: float\n",
        "        The mean of the final distribution.\n",
        "    stdev: float\n",
        "        The standard deviation of the final distribution.\n",
        "    means: [float]\n",
        "        A list of the consecutive distribution means, including the prior's and\n",
        "        the ones resulting from every intermediate step.\n",
        "    stdevs: [float]\n",
        "        A list of the consecutive distribution standard deviations, including \n",
        "        the prior's and the ones resulting from every intermediate step.\n",
        "    '''\n",
        "    mean, stdev = SMCparameters(distribution)\n",
        "    means, stdevs = [], []\n",
        "    means.append(mean)\n",
        "    stdevs.append(stdev) \n",
        "\n",
        "    for i in range(len(data)):\n",
        "        # Update the distribution: get the posterior of the current iteration, \n",
        "        #which is the prior for the next.\n",
        "        distribution = bayes_update(data[:(i+1)],distribution) \n",
        "        \n",
        "        mean,stdev = SMCparameters(distribution)\n",
        "        means.append(mean)\n",
        "        stdevs.append(stdev) \n",
        "    ts = [0] + [datum[0] for datum in data]\n",
        "    cumulative_times = np.cumsum(ts)\n",
        "        \n",
        "    return distribution, (means, stdevs, cumulative_times)\n",
        "    \n",
        "def expected_utility(distribution, time):\n",
        "    '''\n",
        "    Returns the expectation value for the utility of a measurement time.\n",
        "    The utility function considered is a weighed sum of the negative variances\n",
        "    of the two parameters, adjusted for their relative scale.\n",
        "    Its expectation value is computed over all outcomes, given the current\n",
        "    distribution.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    distribution: dict\n",
        "        , with (key,value):=(particle,importance weight) \n",
        "        The prior distribution (SMC approximation).\n",
        "    time: float\n",
        "        The measurement time for which the utility is to be computed.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    utility: float\n",
        "        The expectation value for the utility of the provided measurement time. \n",
        "    '''\n",
        "    # Obtain the probability of each oucome, given the current distribution.\n",
        "    p1=0\n",
        "    for particle in distribution:\n",
        "        weight = distribution[particle]\n",
        "        p1 += likelihood((time,1),particle)*weight\n",
        "    p0 = 1-p1\n",
        "        \n",
        "    dist_0 = copy.deepcopy(distribution)\n",
        "    dist_1 = copy.deepcopy(distribution)\n",
        "    \n",
        "    # Update the distribution assuming each of the possible outcomes (no \n",
        "    #resampling).\n",
        "    dist_0 = bayes_update([(time,0)],dist_0, threshold=0) \n",
        "    dist_1 = bayes_update([(time,1)],dist_1, threshold=0)\n",
        "    \n",
        "    # Compute the expected utility for each oucome.\n",
        "    stdev_0 = SMCparameters(dist_0)[1]\n",
        "    stdev_1 = SMCparameters(dist_1)[1]\n",
        "    \n",
        "    # Calculate the expected utility over all (both) outcomes.\n",
        "    utility = p0*stdev_0 + p1*stdev_1\n",
        "    \n",
        "    return(utility)\n",
        "\n",
        "first_adaptive_guess = True\n",
        "def adaptive_guess(distribution, k, guesses, stdev, gaussian = True, \n",
        "                   spread = 0.25):\n",
        "    '''\n",
        "    Provides a guess for the evolution time to be used for a measurement,\n",
        "    picked using the PGH, a particle guess heuristic (where the times are \n",
        "    chosen to be inverse to the distance between two particles sampled at \n",
        "    random from the distribution).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    distribution: dict\n",
        "        , with (key,value):=(particle,importance weight) \n",
        "        The prior distribution (SMC approximation).\n",
        "    k: float\n",
        "        The proportionality constant to be used for the particle guess \n",
        "        heuristic.\n",
        "    guesses: int\n",
        "        The amount of hypothesis to be picked for the time using the PGH; only \n",
        "        the one which maximizes the expected utility among this set will be  \n",
        "        chosen.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    adaptive_t: float\n",
        "        The measurement time to be used.\n",
        "    '''\n",
        "    global first_adaptive_guess\n",
        "    if first_adaptive_guess:\n",
        "        strategy = (\"normal pick N(1/σ_curr,(1/σ_curr)*%.2f)\" % spread) if gaussian else \\\n",
        "                            \"distance between 2 randomly picked particles\"\n",
        "        print(\"Utility maximization: %d guesses (using %s for variability)\" \n",
        "              \" [adaptive_guess]\" % \n",
        "              (guesses,strategy))\n",
        "        first_adaptive_guess = False\n",
        "\n",
        "    adaptive_ts, utilities = [], []\n",
        "    for i in range(guesses):\n",
        "        delta=0\n",
        "        if gaussian:\n",
        "          if stdev==0:\n",
        "              print(\"> σ=0, can't divide to get the time! [adaptive_guess]\")\n",
        "          mean = k/stdev\n",
        "          time = -1\n",
        "          while(time < 0):\n",
        "              time = np.random.normal(mean,scale = mean*spread)\n",
        "        else:\n",
        "          while (delta==0):\n",
        "            [f1, f2] = random.choices(list(distribution.keys()), \n",
        "                                      weights=distribution.values(), k=2)\n",
        "            delta = abs(f1-f2)\n",
        "          time = k/delta\n",
        "\n",
        "        if (guesses==1):\n",
        "            return(time)\n",
        "        adaptive_ts.append(time)\n",
        "\n",
        "    for t in adaptive_ts:\n",
        "        utilities.append(expected_utility(distribution,t))\n",
        "\n",
        "    chosen_t = adaptive_ts[np.argmin(utilities)]\n",
        "    return(chosen_t)\n",
        "\n",
        "first_adaptive_estimation = True\n",
        "def adaptive_estimation(distribution, steps, run, k=1, guesses=20, precision=0, \n",
        "                        real_data = False):\n",
        "    '''\n",
        "    Estimates the precession frequency by adaptively performing a set of \n",
        "    experiments, using the outcome of each to update the prior distribution \n",
        "    (using Bayesian inference) as well as to decide the next experiment to be \n",
        "    performed.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    distribution: dict\n",
        "        , with (key,value):=(frequency particle,importance weight)\n",
        "        The prior distribution (SMC approximation).\n",
        "    steps: int\n",
        "        The maximum number of experiments to be performed.\n",
        "    k: float, optional\n",
        "        The proportionality constant to be used for the particle guess \n",
        "        heuristic (Default is 1.25).\n",
        "    guesses: int, optional\n",
        "        The amount of hypothesis to be picked for the time; only the one which      \n",
        "        maximizes the expected utility among this set will be chosen (Default \n",
        "        is 1).\n",
        "        If this quantity is greater than one, the times will be chosen to be \n",
        "        inversely proportional to the distance between two particles picked at\n",
        "        random from the current distribution (instead of to its standard \n",
        "        deviation), in order to introduce variability.\n",
        "    precision: float, optional\n",
        "        The threshold precision required to stop the learning process before  \n",
        "        attaining the step number limit (Default is 0).\n",
        "        \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    mean: float\n",
        "        The mean of the final distribution.\n",
        "    stdev: float\n",
        "        The standard deviation of the final distribution.\n",
        "    means: [float]\n",
        "        A list of the consecutive distribution means, including the prior's and\n",
        "        the ones resulting from every intermediate step.\n",
        "    stdevs: [float]\n",
        "        A list of the consecutive distribution standard deviations, including \n",
        "        the prior's and the ones resulting from every intermediate step.\n",
        "    '''\n",
        "    global first_adaptive_estimation\n",
        "    if first_adaptive_estimation is True:\n",
        "        data_source = (\"\" if real_data else \"not \") + \"using real data\"\n",
        "        print(\"Adaptive estimation: k=%.2f; %d guess(es) per step; %s\" % \n",
        "              (k,guesses,data_source))\n",
        "        first_adaptive_estimation = False\n",
        "\n",
        "    mean, stdev = SMCparameters(distribution)\n",
        "    means, stdevs, adaptive_ts = [], [], []\n",
        "    means.append(mean)\n",
        "    stdevs.append(stdev)\n",
        "    adaptive_ts.append(0)\n",
        "    data = []\n",
        "    \n",
        "    if (guesses==1):\n",
        "        adaptive_t = k/stdev\n",
        "    else:\n",
        "        adaptive_t = adaptive_guess(distribution, k, guesses, stdev)\n",
        "        \n",
        "    adaptive_ts.append(adaptive_t)\n",
        "        \n",
        "    for i in range(1,steps+1):\n",
        "        data.append((adaptive_t, measure(adaptive_t,real_data = real_data)))\n",
        "        # Update the distribution: get the posterior of the current iteration, \n",
        "        #which is the prior for the next.\n",
        "        if real_data:\n",
        "            print(\"> Step %d (run %d). [adaptive_estimation]\" % (i,run))\n",
        "\n",
        "        distribution = bayes_update(data,distribution)\n",
        "        \n",
        "        mean,stdev = SMCparameters(distribution)\n",
        "        means.append(mean)\n",
        "        stdevs.append(stdev) \n",
        "        if (stdev <= precision): \n",
        "            break\n",
        "            \n",
        "        if (guesses==1):\n",
        "            adaptive_t = k/stdev\n",
        "        else:\n",
        "            adaptive_t = adaptive_guess(distribution, k, guesses, stdev)\n",
        "        adaptive_ts.append(adaptive_t)\n",
        "    \n",
        "    cumulative_times = np.cumsum(adaptive_ts)\n",
        "    return distribution, (means, stdevs, cumulative_times)\n",
        "\n",
        "def print_resampler_stats(runs,steps):\n",
        "    global total_HMC, accepted_HMC, total_MH, accepted_MH\n",
        "    resampler_calls = (total_HMC + total_MH)/N_particles\n",
        "    if runs!=0 and steps!=0:\n",
        "        print(\"* Average number of resampler calls: %d (%d%%).\" \n",
        "              % (resampler_calls/runs,round(100*resampler_calls/(runs*steps))))\n",
        "    else:\n",
        "        print(\"Steps = %d, runs = %d, so no resampler calls.\" % (steps,runs))\n",
        "    if (total_HMC != 0) or (total_MH != 0):\n",
        "      print(\"* Percentage of HMC steps:  %.1f%%.\" \n",
        "            % (100*total_HMC/(total_HMC+total_MH)))\n",
        "    if (total_HMC != 0):\n",
        "        print(\"* Hamiltonian Monte Carlo: %d%% mean particle acceptance rate.\" \n",
        "              % round(100*accepted_HMC/total_HMC))\n",
        "    if (total_MH != 0):\n",
        "        print(\"* Metropolis-Hastings:     %d%% mean particle acceptance rate.\" \n",
        "              % round(100*accepted_MH/total_MH))\n",
        "    total_HMC, accepted_HMC, total_MH, accepted_MH = 0, 0, 0, 0\n",
        "\n",
        "def get_data(upload=False, filename=None, every=1, steps=75, rep=1, rev=False,\n",
        "             tmin=0.02, tmax=3.5, rand=False, print_info=True):\n",
        "    '''\n",
        "    Provides a data vector for the inference, either by loading it from a file \n",
        "    or by generating it.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    upload: bool, optional\n",
        "        Whether to load the data stored in a file (Default is False).\n",
        "    filename: str, optional\n",
        "        The name of the file from where the data should be loaded if 'upload' is\n",
        "        True (Default is None).\n",
        "    steps: int, optional\n",
        "        The number of measurements to perform if upload is False (Default is \n",
        "        75).\n",
        "    tmax: float, optional\n",
        "        The maximum evolution time to be used if upload is False (Default is \n",
        "        3.5).\n",
        "    rand: bool, optional\n",
        "        Whether to choose the evolution times at random from [0,tmax[ if upload \n",
        "        is False (Default us False, the times will be spaced evenly instead).\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    data: [(float,int)]\n",
        "        A vector of (evolution time, outcome) tuples.\n",
        "    '''\n",
        "    if upload:\n",
        "        print(\"> Uploading data from file \\'%s\\'...\" % filename)\n",
        "        with open(filename, 'rb') as filehandle: \n",
        "            data = pickle.load(filehandle)\n",
        "            # Overwrite step number and maximum time.\n",
        "            steps, tmax = len(data), max([t for t,outcome in data])\n",
        "            # Flip the outcomes because the code is structured oppositely to\n",
        "            #the IBM experiments.\n",
        "            data = [(t,outcome^1) for t,outcome in data]\n",
        "            data = data[::every]\n",
        "            if rev:\n",
        "                data = data[::-1]\n",
        "            steps, tmin, tmax = len(data), min([t for t,outcome in data]), \\\n",
        "                max([t for t,outcome in data])\n",
        "    else:\n",
        "        if rand:\n",
        "            ts = [random.uniform(tmin,tmax) for i in range(steps)]\n",
        "        else:\n",
        "            ts = np.linspace(tmin,tmax,steps)\n",
        "            ts = np.repeat(ts,rep)\n",
        "        if print_info:\n",
        "            print((\"> Using randomly generated \" if rand else \n",
        "                  \"> Using evenly spaced ordered \") + \"times.\")\n",
        "        data = [(t,measure(t)) for t in ts]\n",
        "        if rev:\n",
        "          data = data[::-1]\n",
        "    print(\"Data vector:\", data)\n",
        "    if print_info:\n",
        "        print(\"> t∈[%.1f,%.1f[; steps = %d; f∈[%.1f,%.1f[\" \n",
        "              % (tmin,tmax,steps,fmin,fmax))\n",
        "    return data,steps\n",
        "\n",
        "def show_results(off_runs, off_errors, off_mses, steps, runs, axs, label, color,\n",
        "                 precision = False):\n",
        "    '''\n",
        "    The indexes in adapt_runs/off_runs are, by order: \n",
        "        - Run number;\n",
        "        - Desired quantity (0 for mean, 1 for stdev, 2 for cumulative_time)\n",
        "        - Step number\n",
        "    '''\n",
        "\n",
        "    off_stdevs = [np.percentile([s[i] for m,s,t in off_runs],\n",
        "                                  50,interpolation='nearest') \\\n",
        "                   for i in range(steps+1)]\n",
        "        \n",
        "    final_off_stdevs = [s[steps] for m,s,t in off_runs]\n",
        "    median_final_off_stdevs_index = final_off_stdevs.index(off_stdevs[steps])\n",
        "    off_error = off_errors[median_final_off_stdevs_index]\n",
        "    off_mse = np.median(off_mses)\n",
        "        \n",
        "    off_times = [np.median([t[i] for m,s,t in off_runs]) \\\n",
        "                   for i in range(steps+1)]\n",
        "    off_precisions_all = [([s[i]**2*t[i] for i in range(steps+1)]) \\\n",
        "                   for m,s,t in off_runs]\n",
        "    off_precisions = [np.median([off_precisions_all[i][j] \\\n",
        "                      for i in range(runs)]) for j in range(steps+1)]\n",
        "    \n",
        "    off_stdevs_q1s = [np.percentile([s[i] for m,s,t in off_runs], 25) \\\n",
        "                        for i in range(steps+1)]\n",
        "    off_stdevs_q3s = [np.percentile([s[i] for m,s,t in off_runs], 75) \\\n",
        "                        for i in range(steps+1)]\n",
        "    off_precisions_q1s = [np.percentile([off_precisions_all[i][j] \\\n",
        "                                           for i in range(runs)], 25) \\\n",
        "                            for j in range(steps+1)]\n",
        "    off_precisions_q3s = [np.percentile([off_precisions_all[i][j] \\\n",
        "                                           for i in range(runs)], 75) \\\n",
        "                            for j in range(steps+1)]\n",
        "    \n",
        "    print(\"%s:\\n- Variance: %.6f\\n\"\n",
        "               \"- MSE:      %.6f (deviation %.4f)\\n\"\\\n",
        "          \"- Final precision: %.4f\" \n",
        "          % (label,\n",
        "            off_stdevs[steps]**2, \n",
        "            off_mse,\n",
        "            off_error,\n",
        "            off_precisions[steps]))\n",
        "    \n",
        "    print(\"(particles=%d; steps=%d; fmax=%d; runs=%d; 1d, SMC)\" \n",
        "          % (N_particles,steps,fmax,runs))\n",
        "    \n",
        "    x1 = np.array([i for i in range(steps+1)])\n",
        "    y1 = np.array([off_stdevs[i] for i in range(steps+1)])\n",
        "    axs[0][0].plot(x1, y1, color=color, label=label)\n",
        "    q11 = np.array([off_stdevs_q1s[i] for i in range(steps+1)])\n",
        "    q31 = np.array([off_stdevs_q3s[i] for i in range(steps+1)])\n",
        "    axs[0][0].fill_between(x1,q11,q31,alpha=0.1,color=color)\n",
        "\n",
        "    if precision:\n",
        "        x2 = np.array([off_times[i] for i in range(1,steps+1)])\n",
        "        y2 = np.array([off_precisions[i] for i in range(1,steps+1)])\n",
        "        q12 = np.array([off_precisions_q1s[i] for i in range(1,steps+1)])\n",
        "        q32 = np.array([off_precisions_q3s[i] for i in range(1,steps+1)])\n",
        "        axs[1][0].loglog(x2, y2,color=color, label=label)\n",
        "        axs[1][0].fill_between(x2,q12,q32,alpha=0.1,color=color)\n",
        "\n",
        "def arrange_plots(fig,axs,precision=False):\n",
        "    axs[0][0].set_ylabel(r'$\\sigma$')\n",
        "    \n",
        "    axs[0][0].set_title('Adaptive vs. Offline Estimation')\n",
        "    axs[0][0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    axs[0][0].set_xlabel('Iteration number')\n",
        "\n",
        "    if precision:\n",
        "        axs[1][0].set_ylabel(r'$\\sigma^2 \\cdot \\Delta t$')\n",
        "        axs[1][0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "        axs[1][0].set_xlabel('Total evolution time')\n",
        "    \n",
        "    fig.subplots_adjust(hspace=0.15)\n",
        "\n",
        "def meansquarederror(distribution, f_real):\n",
        "    '''\n",
        "    Calculates the mean squared error given an SMC distribution.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    distribution: dict\n",
        "        , with (key,value):=(particle,importance weight) \n",
        "        , and particle=[f,alpha]:=[frequency,decay factor] (as a bit string)\n",
        "        The distribution (SMC approximation) whose parameters are to be \n",
        "        calculated. This can also be a list if the weights are uniform.\n",
        "    real_parameters: [float]\n",
        "        The set of real parameters.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    r: [float]\n",
        "        The list of mean squared errors along each dimension (for each \n",
        "        parameter).\n",
        "    '''\n",
        "    r = 0\n",
        "    for particle in distribution:\n",
        "        w = distribution[particle]\n",
        "        r += (particle-f_real)**2*w\n",
        "    return r\n",
        "\n",
        "def run_offline_estimation(runs, steps, fs, prior, datasets=None):\n",
        "    global f_real\n",
        "    print(\"> Running offline estimation.\")\n",
        "    print(\"|0%\",end=\"|\"); progress_interval = 100/runs; counter = 0\n",
        "    off_runs, off_errors, off_mses = [], [], []\n",
        "    means, stds = [], []\n",
        "    for i in range(runs):\n",
        "        f_real = fs[i] if np.size(fs)>1 else fs[0]\n",
        "        # if datasets is None:\n",
        "        #   data,steps = get_data(filename=filename, every=1, upload=True, \n",
        "        #                       steps=steps, rep=1, rev=False, tmin=0.2, tmax=tmax, \n",
        "        #                       rand=False, print_info=(True if i==0 else False))\n",
        "        data = datasets[i]\n",
        "\n",
        "        final_dist, off_run = offline_estimation(copy.deepcopy(prior),data)\n",
        "\n",
        "        final_mean, final_std = SMCparameters(final_dist)\n",
        "        means.append(final_mean); stds.append(final_std)\n",
        "\n",
        "        off_runs.append(off_run)\n",
        "        off_errors.append(abs(off_runs[i][0][steps-1]-f_real))\n",
        "        off_mses.append(meansquarederror(final_dist, f_real))\n",
        "        \n",
        "        if runs < 10:\n",
        "            counter+=progress_interval\n",
        "            print(round(counter),\"%\",sep=\"\",end=\"|\")\n",
        "        elif (i%(runs/10)<1): \n",
        "            counter+=10\n",
        "            print(counter,\"%\",sep=\"\",end=\"|\")\n",
        "\n",
        "    print(\"\\n-----\")\n",
        "    print(\"Offline results (%d steps, median over %d runs):\" % (steps,runs))\n",
        "    print(\"- f = %.6f ± %.6f\" % (np.median(means),np.median(stds))) \n",
        "    print(\"-----\")\n",
        "    print_resampler_stats(runs,steps)\n",
        "    return off_runs, off_errors, off_mses, np.median(stds)\n",
        "\n",
        "def run_adaptive_estimation(runs, steps, fs, prior, real_data):\n",
        "    global f_real\n",
        "    print(\"> Running adaptive estimation.\")\n",
        "    print(\"|0%\",end=\"|\"); progress_interval = 100/runs; counter = 0\n",
        "    adapt_runs, adapt_errors, adapt_mses = [], [], []\n",
        "    means, stds = [], []\n",
        "\n",
        "    i = 0\n",
        "    while i != runs:\n",
        "        f_real = fs[i] if np.size(fs)>1 else fs[0]\n",
        "        try:\n",
        "          final_dist, adapt_run = adaptive_estimation(copy.deepcopy(prior),\n",
        "                                                      steps,\n",
        "                                                      i,\n",
        "                                                      real_data=real_data)\n",
        "        except KeyboardInterrupt as err:\n",
        "            print(\"> Keyboard interrupt, breaking from cycle... [run_adaptive_estimation]\")\n",
        "            break\n",
        "        except SystemExit as err:\n",
        "            print(\"> System exit [run_adaptive_estimation] \")\n",
        "            print(err)\n",
        "            break\n",
        "        except Exception as err:\n",
        "            print(\"> Error at run number %d [run_adaptive_estimation].\" % i)\n",
        "            print(err)\n",
        "            continue\n",
        "\n",
        "        final_mean, final_std = SMCparameters(final_dist)\n",
        "        means.append(final_mean); stds.append(final_std)\n",
        "\n",
        "        adapt_runs.append(adapt_run)\n",
        "        adapt_errors.append(abs(adapt_runs[i][0][steps-1]-f_real))\n",
        "        adapt_mses.append(meansquarederror(final_dist, f_real))\n",
        "\n",
        "        i += 1\n",
        "        if runs < 10:\n",
        "            counter+=progress_interval\n",
        "            print(round(counter),\"%\",sep=\"\",end=\"|\")\n",
        "        elif (i%(runs/10)<1): \n",
        "            counter+=10\n",
        "            print(counter,\"%\",sep=\"\",end=\"|\")\n",
        "\n",
        "    print(\"\\n-----\")\n",
        "    print(\"Adaptive results (%d steps, median over %d runs):\" % (steps,runs))\n",
        "    print(\"- f = %.6f ± %.6f\" % (np.median(means),np.median(stds))) \n",
        "    print(\"-----\")\n",
        "    print_resampler_stats(runs,steps)\n",
        "    return adapt_runs, adapt_errors, adapt_mses, steps\n",
        "\n",
        "def run_adaptive_single(steps, fs, prior, real_data, tol=0):\n",
        "    global f_real\n",
        "    print(\"> Running adaptive estimation (single run).\")\n",
        "    adapt_runs, adapt_errors, adapt_mses = [], [], []\n",
        "    means, stds = [], []\n",
        "\n",
        "    f_real = fs[0] \n",
        "    final_dist, adapt_run = adaptive_estimation(copy.deepcopy(prior),steps,0,\n",
        "                                                precision=tol, real_data=real_data)\n",
        "    final_mean, final_std = SMCparameters(final_dist)\n",
        "    means.append(final_mean); stds.append(final_std)\n",
        "\n",
        "    adapt_runs.append(adapt_run)\n",
        "    adapt_errors.append(abs(adapt_run[0][-1]-f_real))\n",
        "    adapt_mses.append(meansquarederror(final_dist, f_real))\n",
        "            \n",
        "    steps = len(adapt_run[0])-1 # If interrupted due to hitting tolerance level.\n",
        "    print(\"-----\")\n",
        "    print(\"Adaptive results (%d steps, single run):\" % steps)\n",
        "    print(\"- f = %.6f ± %.6f\" % (final_mean,final_std)) \n",
        "    print(\"- Variance = %.6f (deviation %.4f)\" % (final_std**2,adapt_errors[-1]))\n",
        "    print(\"- MSE    =   %.6f \" % adapt_mses[-1])\n",
        "    print(\"-----\")\n",
        "    print_resampler_stats(1,steps)\n",
        "    return adapt_runs, adapt_errors, adapt_mses, steps\n",
        "    \n",
        "def generate_dataset_list(ndatasets, steps, tmin, tmax, rep=1):\n",
        "    datasets = []\n",
        "    for i in range(ndatasets):\n",
        "        data,steps = get_data(filename=None, every=1, upload=False, \n",
        "                              steps=steps, rep=1, rev=False, tmin=tmin, \n",
        "                              tmax=tmax, rand=False)\n",
        "        datasets.append(data)\n",
        "    return datasets \n",
        "\n",
        "def upload_dataset_list(filename_start, ndatasets, each):\n",
        "    datasets = []\n",
        "    for i in range(ndatasets):\n",
        "        filename = filename_start + str(i) + '.data'\n",
        "        data,steps = get_data(filename=filename, every=1, upload=True, \n",
        "                              steps=75, rep=1, rev=False, tmin=0.2, \n",
        "                              tmax=5, rand=False)\n",
        "        datasets.extend([data for i in range(each)])\n",
        "    return datasets,steps \n",
        "\n",
        "def match_stdev(upload = False):\n",
        "    global f_real\n",
        "    f_real = 1.83\n",
        "    fs = np.linspace(fmin, fmax, N_particles) \n",
        "    prior = {}\n",
        "    for f in fs:\n",
        "        prior[f] = 1/N_particles # We consider a flat prior up to fmax.\n",
        "    \n",
        "    if upload:\n",
        "      filename_start = 'armonk_echoed_ramsey_data[0.2,2[f=1.83_sched=30_nshots=1_'\n",
        "      datasets, steps = upload_dataset_list(filename_start, 10, 1)\n",
        "      runs = len(datasets)\n",
        "    else: \n",
        "      runs = 3\n",
        "      steps = 30\n",
        "      datasets = generate_dataset_list(runs, steps, tmin=0.2, tmax=2, rep=1)\n",
        "\n",
        "    real_fs = [1.83]\n",
        "    off_runs, off_errors, off_mses, median_std = run_offline_estimation(\n",
        "                                                            runs, \n",
        "                                                            steps,\n",
        "                                                            real_fs, \n",
        "                                                            copy.deepcopy(prior),\n",
        "                                                            datasets=datasets)\n",
        "    \n",
        "    precision = True\n",
        "    fig, axs = plt.subplots(2 if precision else 1,\n",
        "                            figsize=(12,12 if precision else 8), \n",
        "                            squeeze=False)\n",
        "    show_results(off_runs, off_errors, off_mses, steps, runs, axs, \n",
        "                 'Offline', 'red', precision=precision)\n",
        "\n",
        "    n_adapt_runs = runs # Will take the run with mean number of steps.\n",
        "    adapt_runs, adapt_errors, adapt_mses, steps_taken = [], [], [], []\n",
        "    try:\n",
        "      for i in range(n_adapt_runs):\n",
        "          print(\"> Single run %d [match_stdev]\" % i)\n",
        "          # These will all be single element lists.\n",
        "          adapt_run, adapt_error, adapt_mse, astep = run_adaptive_single(\n",
        "                                                                        steps,\n",
        "                                                                        real_fs,\n",
        "                                                                        copy.deepcopy(prior),\n",
        "                                                                        real_data = True,\n",
        "                                                                        tol = median_std)\n",
        "          \n",
        "          # And these lists of length 1 lists except for the steps.\n",
        "          adapt_runs.append(adapt_run)\n",
        "          adapt_errors.append(adapt_error)\n",
        "          adapt_mses.append(adapt_mse)\n",
        "          steps_taken.append(astep)\n",
        "\n",
        "          # adapt_runs.extend(adapt_run)\n",
        "          # adapt_errors.extend(adapt_error)\n",
        "          # adapt_mses.extend(adapt_mse)\n",
        "          # steps_taken.append(astep)\n",
        "    except:\n",
        "      err = sys.exc_info()[0]\n",
        "      n_adapt_runs = len(steps_taken)\n",
        "      print(\"> Quit at run %d (%s).\" % (runs,err))\n",
        "\n",
        "    # show_results(adapt_runs, adapt_errors, adapt_mses, steps, n_adapt_runs, axs, \n",
        "    #              'Adaptive', 'blue', precision=precision, up_to_step=median_steps)\n",
        "\n",
        "    if n_adapt_runs != 0:\n",
        "        median_steps = np.percentile(steps_taken,50,interpolation='nearest')\n",
        "        med_step_index = steps_taken.index(median_steps)\n",
        "        med_adapt_run, med_adapt_error, med_adapt_mse = (adapt_runs[med_step_index],\n",
        "                                                        adapt_errors[med_step_index],\n",
        "                                                        adapt_mses[med_step_index])\n",
        "\n",
        "        if median_steps<steps:\n",
        "            print(\"> Adaptive estimation run took %d steps to match offline estimation's\"\n",
        "            \" final variance (median number).\" % median_steps)\n",
        "\n",
        "        show_results(med_adapt_run, med_adapt_error, med_adapt_mse, median_steps,\n",
        "                    1, axs, 'Adaptive', 'blue', precision=precision)\n",
        "        \n",
        "    arrange_plots(fig, axs, precision=precision)\n",
        "\n",
        "def run_both():\n",
        "    global f_real\n",
        "    fs = np.linspace(fmin, fmax, N_particles) \n",
        "    prior = {}\n",
        "    for f in fs:\n",
        "        prior[f] = 1/N_particles # We consider a flat prior up to fmax.\n",
        "    real_fs = [1.83]\n",
        "\n",
        "    real_data = True\n",
        "    if real_data:\n",
        "      filename_start = 'armonk_echoed_ramsey_data[0.2,2[f=1.83_sched=15_nshots=1_'\n",
        "      datasets, steps = upload_dataset_list(filename_start, 100, 1)\n",
        "      runs = len(datasets)\n",
        "    else: \n",
        "      f_real = real_fs[0]\n",
        "      runs = 5\n",
        "      steps = 15\n",
        "      datasets = generate_dataset_list(runs, steps, tmin=0.2, tmax=2, rep=1)\n",
        "\n",
        "    \n",
        "    off_runs, off_errors, off_mses, median_std = run_offline_estimation(\n",
        "                                                            runs, \n",
        "                                                            steps,\n",
        "                                                            real_fs, \n",
        "                                                            copy.deepcopy(prior),\n",
        "                                                            datasets = datasets)\n",
        "    adapt_runs, adapt_errors, adapt_mses, asteps = run_adaptive_estimation(\n",
        "                                                                   runs,\n",
        "                                                                   steps,\n",
        "                                                                   real_fs,\n",
        "                                                                   copy.deepcopy(prior),\n",
        "                                                                   real_data = real_data)\n",
        "\n",
        "    precision = True\n",
        "    fig, axs = plt.subplots(2 if precision else 1,\n",
        "                            figsize=(12,12 if precision else 8), \n",
        "                            squeeze=False)\n",
        "    show_results(off_runs, off_errors, off_mses, steps, runs, axs, \n",
        "                 'Offline', 'red',precision=precision)\n",
        "    show_results(adapt_runs, adapt_errors, adapt_mses, asteps, runs, axs, \n",
        "                 'Adaptive', 'blue',precision=precision)\n",
        "    arrange_plots(fig, axs,precision=precision)\n",
        "    print(\"(n=%d; N=%d; fmax=%d; runs=%d; 1d, SMC)\" \n",
        "          % (N_particles,steps,fmax,runs))\n",
        "    plt.savefig('graph.pdf')  \n",
        "    files.download('graph.pdf')  \n",
        "\n",
        "run_both()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Using evenly spaced ordered times.\n",
            "Data vector: [(0.2, 1), (0.2620689655172414, 0), (0.32413793103448274, 0), (0.38620689655172413, 1), (0.4482758620689655, 1), (0.5103448275862069, 1), (0.5724137931034483, 1), (0.6344827586206896, 0), (0.6965517241379311, 1), (0.7586206896551724, 0), (0.8206896551724139, 0), (0.8827586206896552, 0), (0.9448275862068964, 1), (1.006896551724138, 0), (1.0689655172413792, 1), (1.1310344827586207, 1), (1.193103448275862, 1), (1.2551724137931033, 1), (1.3172413793103448, 0), (1.379310344827586, 0), (1.4413793103448276, 0), (1.5034482758620689, 0), (1.5655172413793104, 1), (1.6275862068965516, 1), (1.689655172413793, 1), (1.7517241379310344, 0), (1.8137931034482757, 0), (1.8758620689655172, 0), (1.9379310344827585, 0), (2.0, 0)]\n",
            "> t∈[0.2,2.0[; steps = 30; f∈[0.0,10.0[\n",
            "> Using evenly spaced ordered times.\n",
            "Data vector: [(0.2, 0), (0.2620689655172414, 0), (0.32413793103448274, 0), (0.38620689655172413, 0), (0.4482758620689655, 1), (0.5103448275862069, 1), (0.5724137931034483, 1), (0.6344827586206896, 0), (0.6965517241379311, 1), (0.7586206896551724, 0), (0.8206896551724139, 0), (0.8827586206896552, 0), (0.9448275862068964, 0), (1.006896551724138, 0), (1.0689655172413792, 1), (1.1310344827586207, 1), (1.193103448275862, 0), (1.2551724137931033, 1), (1.3172413793103448, 0), (1.379310344827586, 0), (1.4413793103448276, 0), (1.5034482758620689, 0), (1.5655172413793104, 1), (1.6275862068965516, 1), (1.689655172413793, 1), (1.7517241379310344, 1), (1.8137931034482757, 1), (1.8758620689655172, 0), (1.9379310344827585, 0), (2.0, 0)]\n",
            "> t∈[0.2,2.0[; steps = 30; f∈[0.0,10.0[\n",
            "> Using evenly spaced ordered times.\n",
            "Data vector: [(0.2, 0), (0.2620689655172414, 0), (0.32413793103448274, 0), (0.38620689655172413, 0), (0.4482758620689655, 1), (0.5103448275862069, 1), (0.5724137931034483, 1), (0.6344827586206896, 1), (0.6965517241379311, 0), (0.7586206896551724, 0), (0.8206896551724139, 0), (0.8827586206896552, 0), (0.9448275862068964, 0), (1.006896551724138, 1), (1.0689655172413792, 1), (1.1310344827586207, 1), (1.193103448275862, 0), (1.2551724137931033, 1), (1.3172413793103448, 1), (1.379310344827586, 0), (1.4413793103448276, 0), (1.5034482758620689, 0), (1.5655172413793104, 1), (1.6275862068965516, 1), (1.689655172413793, 1), (1.7517241379310344, 1), (1.8137931034482757, 0), (1.8758620689655172, 0), (1.9379310344827585, 0), (2.0, 1)]\n",
            "> t∈[0.2,2.0[; steps = 30; f∈[0.0,10.0[\n",
            "> Running offline estimation.\n",
            "|0%|MH:  s=sigma, factor=0.1000\n",
            "33%|67%|100%|\n",
            "-----\n",
            "Offline results (30 steps, median over 3 runs):\n",
            "- f = 1.784649 ± 0.029073\n",
            "-----\n",
            "* Average number of resampler calls: 13 (46%).\n",
            "* Percentage of HMC steps:  0.0%.\n",
            "* Metropolis-Hastings:     48% mean particle acceptance rate.\n",
            "Offline:\n",
            "- Variance: 0.000845\n",
            "- MSE:      0.002688 (deviation 0.0421)\n",
            "- Final precision: 0.0279\n",
            "(particles=100; steps=30; fmax=10; runs=3; 1d, SMC)\n",
            "> Single run 0 [match_stdev]\n",
            "> Running adaptive estimation (single run).\n",
            "Adaptive estimation: k=1.00; 20 guess(es) per step; using real data\n",
            "Utility maximization: 20 guesses (using normal pick N(1/σ_curr,(1/σ_curr)*0.25) for variability) [adaptive_guess]\n",
            "Job Status: job is actively running> Quit at run 3 (<class 'KeyboardInterrupt'>).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}